---
title: "Maths Grades Analysis"
output:
  html_document:
    df_print: paged
  pdf_document: default
  word_document: default
editor_options:
  chunk_output_type: inline
chunk_output_type: inline
---
```{r,echo=FALSE}
Name <- c("Annabelle Griffith-Topps","Jake White","Bryan Li","Ana Klabjan","Zi Hern Wong","Jacob Larget")
NetID <- c("griffithtopp","jtwhite4","bli378","aklabjan","zwong4","jlarget")
data.frame(Name,NetID)
```
The data set describes final grades of students and provides a multitude of variables that could correlate with student performance. We found that this data set provided an extensive amount of information about studentâ€™s backgrounds that could hypothetically impact grades, and as students, we thought it could be insightful and allow us to do an in depth analysis of the data. 

```{r,warning=FALSE}
library(tidyverse)
data <- read.csv("student-mat.csv")
head(data,10)
```


```{r}
grades <- data %>% select(G1,G2,G3)
pairs(grades)
cor(grades)
```
```{r}
lmG1 <- lm(G3~G1,data = grades)
lmG2 <- lm(G3~G2,data = grades)
pc <- prcomp(grades[,c(1,2)], scale=TRUE)
lm <- lm(grades$G3 ~ pc$x[,1])
summary(lmG1)
summary(lmG2)
summary(lm)
```

```{r}
sum(residuals(lm)^2)
sum(residuals(lmG1)^2)
sum(residuals(lmG2)^2)
```
```{r}
plot(residuals(lm),xlab="Data Entry Index", ylab="Residual of Lm(G3~PC1)")
abline(h=0,col = "red")
```
There seems to be a strong correlation between the grades students had at the beginning of the year, the middle and the end. This was expected from our data. A linear model seems to be appropriate although when looking at the residual graph there are several outliers on the negative end. This is a pattern to further explore.
```{r}
cols <- character(nrow(grades))
cols[] <- "black"
cols[grades$G3 == 0] <- "red"
pairs(grades,col=cols)

plot(residuals(lm),xlab="Data Entry Index", ylab="Residual of Lm(G3~PC1)",col = cols)
abline(h=0,col = "red")
```
Based on the graphs above we are able to explain the data points that go against the trend of our data. The points in red represent students who got a 0 for there end of the year grade. We can assume those people dropped out after G1 or G2 was reported.

__Analysis of Students Who Dropped__
```{r}
drop <- data %>%
  mutate(dropped = case_when(
    G3 == 0 ~ TRUE,
    G3 > 0 ~ FALSE),
    G1=G1/20,G2=G2/20,G3=G3/20) %>%
  select(dropped,G1,G2,G3,everything())
head(drop,3)
```

We know there is a correlation between G1, G2, and G3 but can we find a pattern to the students who dropped out? Can G1 grades be used to predict which students dropped out? Are there potentially other facts? 

```{r}
drop %>% group_by(dropped) %>% count()
38/(357+38)
```

These questions are important to ask since if we can identify which students are most likely to drop out then analysis can be done on future students and those students who are most likely in danger of dropping out can receive access and resources to additional assistance. This is especially important to our data set when the Portuguese are trying to improve there student failure rate in core classes. Our data set shows that at the time of data collection there was about a 10% drop out rate which is very high. 

```{r}
drop %>%
  filter(drop == TRUE) %>%
  ggplot(aes(G1)) +
  geom_bar() +
  xlab("First Period Grade in Percentage") +
  ylab("Student Count") +
  ggtitle("First Period Grades Among Students Who Dropped")
```

From these two graphs, we can see that among those who dropped at some point in the class, none of them were able to obtain a score higher than ~60%. Now, how does that relate to students who did not drop?

```{r}
ggplot(drop, aes(x=G1, fill=dropped)) +
  geom_density(alpha=.25) +
  xlab("First Period Grade in Percentage") +
  ylab("Density") +
  ggtitle("First Period Grade Density By Dropped Out")

ggplot(drop,aes(x=dropped, y=G1,fill=dropped)) + 
  geom_boxplot() +
  ggtitle("First Period Grade Distribution by Dropped Out")+
  xlab("Students Dropped Out By End of Year")+
  ylab("First Period Grade in Percentage")
```
Compared to students who did not drop the class, we see a noticeable difference between first period grades. While only the highest scoring students among the dropped category were able to score ~60%, the mean of all student's scores during the first period was ~60%. Thus, we can conclude that students that dropped the class can be predicted to do considerably worse than those who did not drop the class. This seems pretty obvious, but could there be other factors that lead to this outcome?



__Modifying Data From Categorical to Representation by Numbers__
```{r}
data2 <- data %>% mutate(address = case_when(address == "U"~ 0,TRUE ~ 1),
                         famsup = case_when(famsup == "no"~0,TRUE~1),
                         higher = case_when(higher == "yes"~ 0, higher == "no" ~ 1),
                         internet = case_when(internet == "yes" ~ 0, internet == "no" ~ 1),
                         famsize = case_when(famsize == "GT3" ~ 0, famsize == "LE3" ~ 1),
                         Pstatus = case_when(Pstatus == "A" ~ 0, famsize == "T" ~ 1),
                         romantic = case_when(romantic == "no" ~ 0, romantic=="yes" ~ 1))%>%
  rename(motherEduation = Medu, fatherEduation = Fedu, parentalStatus=Pstatus)
data2
```

__Analysis of Factors That May Impact Final Grade Prediction__
```{r}
data2 %>% 
  ggplot(aes(x=sex, y=G3,fill=sex)) + 
    geom_boxplot() +
  ggtitle("Final Grades Based On Gender")+
  xlab("Gender(F=Female,M=Male)")+
  ylab("End Of Year Grade")
```
We see that on average males performed better in the math course over females. Being a male is more likely to lead to higher grades.

```{r}
data %>%
  ggplot(aes(x=famsup, y=G3,fill=famsup)) + 
    geom_boxplot() +
  ggtitle("Final Grades Based On Family Education Support")+
  xlab("Recieved Family Education Support")+
  ylab("End Of Year Grade")
```
This was surprising as we would have assumed if students received help at home they would receive higher grades due to that extra assistants. Our boxplot shows that both groups have the same average grade. The students who didn't receive help had a greater variety in Q3 and The students who did receive help on the other hand had greater variety in Q2. This being said we came to the conclusion that recieving help a home has minimal impact on final grades. 

```{r}
data %>% mutate(studytime = case_when(studytime == 1 ~ "<15 min",
                                      studytime == 2 ~ "15 to 30 min",
                                      studytime == 3 ~ "30 min. to 1 hour",
                                      TRUE ~ ">1 hour")) %>%
  ggplot(aes(x=reorder(studytime,G3,na.rm = TRUE), y=G3,fill=studytime)) + 
    geom_boxplot() +
  ggtitle("Final Grades Based Weekly Study Time")+
  xlab("Weekly Study Time")+
  ylab("End Of Year Grade")
```
When looking at this graph we observed that as study time increases so does the average grade although overstudying can be a thing. Over an hour studying was still relatively comparable to 30min-1 hour studying by median but the lower 50 percent was spread out over a greater region on the other hand the top percentile received a higher grade then the top percentile of people who studied 30 minutes to an hour. Given this information we would say that 30 minutes to an hour is the optimal study time per week for this math course. 